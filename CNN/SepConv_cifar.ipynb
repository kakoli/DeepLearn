{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign4_cifar_SepConv.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "####  **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SeparableConv2D\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import backend as k\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist, cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled CIFAR data into train and test sets\n",
        "Plotting sample images from the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "4446eed1-0849-4f79-b415-458b754252f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# X_train - 50000, 32, 32, 3\n",
        "label_dict = {0:\"airplane\", 1:\"automobile\", 2:\"bird\", 3:\"cat\", 4:\"deer\", 5:\"dog\", 6:\"frog\", 7:\"horse\", 8:\"ship\", 9:\"truck\"}\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(2,2)) # width,height\n",
        "\n",
        "for idx in range(2):\n",
        "  sub = fig.add_subplot(1,2, idx+1) # nrows, ncols, index\n",
        "  label = label_dict.get(y_train[idx][0])\n",
        "    \n",
        "  sub.set_title(label)\n",
        "  sub.imshow(X_train[idx])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJUAAABiCAYAAABZNZHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDJhqgG3H/wc6zFp7xWIicgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 144x144 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2flpl1ptOgT",
        "colab_type": "text"
      },
      "source": [
        "One hot encoding the labels from training and test set. Each 1d label is converted to 10d sparse matrix. Eg, digit 2 becomes [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "outputId": "cc718488-399b-4eb8-b2b1-e00963e43ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpGg43Ey2mLH",
        "colab_type": "text"
      },
      "source": [
        "#### 2 models with dropout and BN:\n",
        "\n",
        "* 32-64-128-MP-100-128-256-512-MP-200(1)-100-10. 1.83m params. Best val. accuracy was **78.28% at epoch 19**, train acc 95.49%\n",
        "* 48-96-64(1)-MP-96-192-128(1)-MP-192-384-200(1)-MP-100-10. 1.3m params. Best val. accuracy **82.77% at epoch 19**, train acc 95.21%\n",
        "\n",
        "Second model is chosen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932WQTzj2m2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_first_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, 3, activation='relu', input_shape=(32,32,3), use_bias=False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(64, 3, activation='relu', use_bias=False)) #rf5, 28\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(128, 3, activation='relu', use_bias=False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))    # #rf14, 13 \n",
        "  model.add(Conv2D(100, 1, activation='relu'))\n",
        " \n",
        "  model.add(Conv2D(128, 3, activation='relu', use_bias=False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(256, 3, activation='relu', use_bias=False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(512, 3, activation='relu', use_bias=False))  #rf20, 7\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "    \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))    #rf40, 3\n",
        "  model.add(Conv2D(200, 1, activation='relu'))\n",
        "  model.add(Conv2D(100, 1, activation='relu'))\n",
        "    \n",
        "  model.add(Conv2D(10, 3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1b5wn-EsuY",
        "colab_type": "code",
        "outputId": "e931123c-881d-4000-e5fe-a841c4592d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_first_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_43 (Conv2D)           (None, 30, 30, 32)        864       \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 28, 28, 64)        18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 26, 26, 128)       73728     \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 26, 26, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 13, 13, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 13, 13, 100)       12900     \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 11, 11, 128)       115200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 11, 11, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 9, 9, 256)         294912    \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 9, 9, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 7, 7, 512)         1179648   \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 3, 3, 200)         102600    \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 3, 3, 100)         20100     \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 1, 1, 10)          9010      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,831,874\n",
            "Trainable params: 1,829,634\n",
            "Non-trainable params: 2,240\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 49s 980us/step - loss: 1.4446 - acc: 0.4785 - val_loss: 1.4304 - val_acc: 0.5146\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 47s 940us/step - loss: 1.0160 - acc: 0.6396 - val_loss: 1.2674 - val_acc: 0.5685\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 47s 940us/step - loss: 0.8215 - acc: 0.7101 - val_loss: 0.9654 - val_acc: 0.6765\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.7020 - acc: 0.7553 - val_loss: 0.8329 - val_acc: 0.7119\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 47s 940us/step - loss: 0.6095 - acc: 0.7880 - val_loss: 0.8297 - val_acc: 0.7321\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 47s 938us/step - loss: 0.5291 - acc: 0.8157 - val_loss: 0.7624 - val_acc: 0.7454\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.4677 - acc: 0.8362 - val_loss: 0.7088 - val_acc: 0.7689\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 47s 940us/step - loss: 0.4063 - acc: 0.8570 - val_loss: 0.7737 - val_acc: 0.7571\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 47s 938us/step - loss: 0.3549 - acc: 0.8749 - val_loss: 0.8211 - val_acc: 0.7552\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 47s 938us/step - loss: 0.3060 - acc: 0.8907 - val_loss: 0.9416 - val_acc: 0.7290\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.2652 - acc: 0.9070 - val_loss: 0.8409 - val_acc: 0.7653\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.2365 - acc: 0.9175 - val_loss: 0.8615 - val_acc: 0.7747\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.1962 - acc: 0.9301 - val_loss: 1.0313 - val_acc: 0.7526\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.1828 - acc: 0.9348 - val_loss: 0.9246 - val_acc: 0.7728\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.1626 - acc: 0.9423 - val_loss: 0.9892 - val_acc: 0.7677\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 47s 938us/step - loss: 0.1566 - acc: 0.9454 - val_loss: 1.0487 - val_acc: 0.7682\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 47s 937us/step - loss: 0.1396 - acc: 0.9509 - val_loss: 1.0584 - val_acc: 0.7725\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 47s 938us/step - loss: 0.1286 - acc: 0.9537 - val_loss: 1.0840 - val_acc: 0.7636\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 47s 939us/step - loss: 0.1291 - acc: 0.9549 - val_loss: 1.0459 - val_acc: 0.7828\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 47s 938us/step - loss: 0.1193 - acc: 0.9587 - val_loss: 1.0060 - val_acc: 0.7810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa79368c7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9mqNpVPSWreA",
        "colab": {}
      },
      "source": [
        "def build_second_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(48, 3, padding='same', input_shape=(32, 32, 3), use_bias=False)) #rf 3\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(96, 3, padding='same', use_bias=False)) \n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(64, 1 ))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #16, rf10  \n",
        "\n",
        "  model.add(Conv2D(96, 3, padding='same', use_bias=False))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(192, 3, padding='same', use_bias=False)) #16, rf14\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(128, 1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #8, rf28\n",
        "  \n",
        "  model.add(Conv2D(192, 3, padding='same', use_bias=False))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Conv2D(384, 3, padding='same', use_bias=False))#8, rf32\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(200, 1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #4, rf64\n",
        "   \n",
        "  model.add(Conv2D(100, 1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv2D(10, 4))\n",
        "    \n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8-EDesL7YMm",
        "colab_type": "code",
        "outputId": "94c78088-f1a9-4082-8423-7d7c7a341f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_second_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 48)        1296      \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 32, 32, 48)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 32, 32, 48)        192       \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 32, 32, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 32, 32, 96)        41472     \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 32, 32, 64)        6208      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 16, 16, 96)        55296     \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 16, 16, 192)       165888    \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 16, 16, 128)       24704     \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 8, 8, 192)         221184    \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 8, 8, 384)         663552    \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 8, 8, 200)         77000     \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 8, 8, 200)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 200)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 4, 4, 100)         20100     \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 1, 1, 10)          16010     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,296,742\n",
            "Trainable params: 1,294,726\n",
            "Non-trainable params: 2,016\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 57s 1ms/step - loss: 1.3718 - acc: 0.5088 - val_loss: 1.5090 - val_acc: 0.4849\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.8776 - acc: 0.6893 - val_loss: 1.4422 - val_acc: 0.5459\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.6957 - acc: 0.7576 - val_loss: 0.8708 - val_acc: 0.7102\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.5923 - acc: 0.7932 - val_loss: 0.8429 - val_acc: 0.7232\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.5174 - acc: 0.8176 - val_loss: 0.8838 - val_acc: 0.7130\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.4514 - acc: 0.8430 - val_loss: 0.9233 - val_acc: 0.7079\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.3992 - acc: 0.8598 - val_loss: 0.6893 - val_acc: 0.7716\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.3545 - acc: 0.8750 - val_loss: 0.7419 - val_acc: 0.7561\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.3172 - acc: 0.8888 - val_loss: 0.6689 - val_acc: 0.7839\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.2752 - acc: 0.9028 - val_loss: 0.7075 - val_acc: 0.7870\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.2426 - acc: 0.9147 - val_loss: 0.6681 - val_acc: 0.7979\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.2190 - acc: 0.9224 - val_loss: 0.6988 - val_acc: 0.7930\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1917 - acc: 0.9311 - val_loss: 0.6910 - val_acc: 0.8141\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1830 - acc: 0.9346 - val_loss: 0.6601 - val_acc: 0.8131\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1644 - acc: 0.9418 - val_loss: 0.6884 - val_acc: 0.8136\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1504 - acc: 0.9456 - val_loss: 0.6885 - val_acc: 0.8216\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1392 - acc: 0.9500 - val_loss: 0.7035 - val_acc: 0.8195\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1283 - acc: 0.9547 - val_loss: 0.7950 - val_acc: 0.8099\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1324 - acc: 0.9521 - val_loss: 0.7094 - val_acc: 0.8277\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1170 - acc: 0.9589 - val_loss: 0.8463 - val_acc: 0.8072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa794ce7898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK2VmdXTjnhk",
        "colab_type": "text"
      },
      "source": [
        "#### Using depthwise sep conv in place of normal, parameters dropped to 267K from 1.3m. Best val. accuracy was **81.77% at epoch 20**, train acc 89.54%. Gap between 2 accuracies have reduced as overfitting has reduced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UTti13Lh-6dp",
        "colab": {}
      },
      "source": [
        "def build_depth_sep():\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(SeparableConv2D(48, 3, padding='same', input_shape=(32, 32, 3), use_bias=False)) #rf 3\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(SeparableConv2D(96, 3, padding='same', use_bias=False)) \n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(SeparableConv2D(64, 1 ))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #16, rf10  \n",
        "\n",
        "  model.add(SeparableConv2D(96, 3, padding='same', use_bias=False))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(SeparableConv2D(192, 3, padding='same', use_bias=False)) #16, rf14\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(SeparableConv2D(128, 1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #8, rf28\n",
        "  \n",
        "  model.add(SeparableConv2D(192, 3, padding='same', use_bias=False))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(SeparableConv2D(384, 3, padding='same', use_bias=False))#8, rf32\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(SeparableConv2D(200, 1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #4, rf64\n",
        "   \n",
        "  model.add(SeparableConv2D(100, 1))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(SeparableConv2D(10, 4))\n",
        "    \n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqJVopqrKZYt",
        "colab_type": "code",
        "outputId": "3ec03038-5cf5-48d3-e386-34dd75cc83da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_depth_sep()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "separable_conv2d_69 (Separab (None, 32, 32, 48)        171       \n",
            "_________________________________________________________________\n",
            "activation_156 (Activation)  (None, 32, 32, 48)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_144 (Bat (None, 32, 32, 48)        192       \n",
            "_________________________________________________________________\n",
            "dropout_144 (Dropout)        (None, 32, 32, 48)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_70 (Separab (None, 32, 32, 96)        5040      \n",
            "_________________________________________________________________\n",
            "activation_157 (Activation)  (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_145 (Bat (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "dropout_145 (Dropout)        (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_71 (Separab (None, 32, 32, 64)        6304      \n",
            "_________________________________________________________________\n",
            "activation_158 (Activation)  (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_68 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_72 (Separab (None, 16, 16, 96)        6720      \n",
            "_________________________________________________________________\n",
            "activation_159 (Activation)  (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_146 (Bat (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "dropout_146 (Dropout)        (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_73 (Separab (None, 16, 16, 192)       19296     \n",
            "_________________________________________________________________\n",
            "activation_160 (Activation)  (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_147 (Bat (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "dropout_147 (Dropout)        (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_74 (Separab (None, 16, 16, 128)       24896     \n",
            "_________________________________________________________________\n",
            "activation_161 (Activation)  (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_69 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_75 (Separab (None, 8, 8, 192)         25728     \n",
            "_________________________________________________________________\n",
            "activation_162 (Activation)  (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_148 (Bat (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "dropout_148 (Dropout)        (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_76 (Separab (None, 8, 8, 384)         75456     \n",
            "_________________________________________________________________\n",
            "activation_163 (Activation)  (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_149 (Bat (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "dropout_149 (Dropout)        (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_77 (Separab (None, 8, 8, 200)         77384     \n",
            "_________________________________________________________________\n",
            "activation_164 (Activation)  (None, 8, 8, 200)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_70 (MaxPooling (None, 4, 4, 200)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_78 (Separab (None, 4, 4, 100)         20300     \n",
            "_________________________________________________________________\n",
            "activation_165 (Activation)  (None, 4, 4, 100)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_79 (Separab (None, 1, 1, 10)          2610      \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_166 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 267,937\n",
            "Trainable params: 265,921\n",
            "Non-trainable params: 2,016\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 51s 1ms/step - loss: 1.5715 - acc: 0.4081 - val_loss: 1.3657 - val_acc: 0.5028\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 42s 844us/step - loss: 1.0916 - acc: 0.6046 - val_loss: 1.0960 - val_acc: 0.6154\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.9251 - acc: 0.6680 - val_loss: 0.8879 - val_acc: 0.6870\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.8237 - acc: 0.7069 - val_loss: 0.8097 - val_acc: 0.7165\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.7443 - acc: 0.7356 - val_loss: 0.8488 - val_acc: 0.7120\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 42s 846us/step - loss: 0.6758 - acc: 0.7597 - val_loss: 0.7980 - val_acc: 0.7338\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.6239 - acc: 0.7799 - val_loss: 0.8792 - val_acc: 0.7023\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.5824 - acc: 0.7960 - val_loss: 0.7177 - val_acc: 0.7578\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 42s 848us/step - loss: 0.5428 - acc: 0.8083 - val_loss: 0.6690 - val_acc: 0.7748\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 42s 846us/step - loss: 0.5075 - acc: 0.8207 - val_loss: 0.7337 - val_acc: 0.7579\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 42s 846us/step - loss: 0.4795 - acc: 0.8319 - val_loss: 0.6316 - val_acc: 0.7919\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 42s 849us/step - loss: 0.4481 - acc: 0.8420 - val_loss: 0.7287 - val_acc: 0.7617\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 43s 851us/step - loss: 0.4256 - acc: 0.8512 - val_loss: 0.6547 - val_acc: 0.7793\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 42s 848us/step - loss: 0.3981 - acc: 0.8591 - val_loss: 0.6652 - val_acc: 0.7799\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.3810 - acc: 0.8663 - val_loss: 0.6627 - val_acc: 0.7820\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 42s 846us/step - loss: 0.3578 - acc: 0.8734 - val_loss: 0.6814 - val_acc: 0.7878\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 42s 846us/step - loss: 0.3398 - acc: 0.8789 - val_loss: 0.5919 - val_acc: 0.8089\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.3194 - acc: 0.8855 - val_loss: 0.6301 - val_acc: 0.8001\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 42s 845us/step - loss: 0.3050 - acc: 0.8918 - val_loss: 0.5948 - val_acc: 0.8088\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 42s 847us/step - loss: 0.2915 - acc: 0.8954 - val_loss: 0.5834 - val_acc: 0.8177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa77afa1cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X89IkUn53lpA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spatial_sep_conv(model, filter_x, filter_out):\n",
        "    l1 = Conv2D(filter_x, (3, 1), activation='relu', padding='same')\n",
        "    model.add(l1)\n",
        "    l2 = Conv2D(filter_out, (1,3), activation='relu', padding='same')    \n",
        "    model.add(l2)\n",
        "    \n",
        "    #l1 type keras.layers.convolutional.Conv2D\n",
        "    #print(l1.output_shape, l2.output_shape)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbY0uHlGWPYJ",
        "colab_type": "text"
      },
      "source": [
        "#### Using spatial sep conv in place of normal, parameters dropped to 740K from 1.3m. Best val. accuracy was **81.05% at epoch 19**, train acc 91.77%.\n",
        "Here paramaters are more than depthwise sep, hence overfitting is slightly more. Depthwise is used mostly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uoI07Ofx-9S9",
        "colab": {}
      },
      "source": [
        "def build_spatial_sep_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Conv2D(48, 3, padding='same', activation='relu', input_shape=(32, 32, 3))) #rf 3\n",
        "  #model = spatial_sep_conv2(model, 3, 48, input_shape=(32, 32, 3))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model = spatial_sep_conv2(model, 48, 96)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))  \n",
        "  \n",
        "  model.add(Conv2D(64, 1, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #16, rf10  \n",
        "  \n",
        "  model = spatial_sep_conv2(model, 64, 96)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model = spatial_sep_conv2(model, 96, 192) #16, rf14\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(128, 1, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #8, rf28\n",
        "  \n",
        "  model = spatial_sep_conv2(model, 128, 192)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  model = spatial_sep_conv2(model, 192, 384) #8, rf32\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.1))\n",
        "  \n",
        "  model.add(Conv2D(200, 1, activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #4, rf64\n",
        "    \n",
        "  model.add(Conv2D(100, 1, activation='relu'))\n",
        "  model.add(Conv2D(10, 4))\n",
        "    \n",
        "  model.add(Flatten())\n",
        "  model.add(Activation('softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piiNb_oWk1Nx",
        "colab_type": "code",
        "outputId": "849ebc51-9e50-4b36-a74c-79c6afd1c8e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model=build_spatial_sep_model()\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_228 (Conv2D)          (None, 32, 32, 48)        1344      \n",
            "_________________________________________________________________\n",
            "batch_normalization_138 (Bat (None, 32, 32, 48)        192       \n",
            "_________________________________________________________________\n",
            "dropout_138 (Dropout)        (None, 32, 32, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_229 (Conv2D)          (None, 32, 32, 48)        6960      \n",
            "_________________________________________________________________\n",
            "conv2d_230 (Conv2D)          (None, 32, 32, 96)        13920     \n",
            "_________________________________________________________________\n",
            "batch_normalization_139 (Bat (None, 32, 32, 96)        384       \n",
            "_________________________________________________________________\n",
            "dropout_139 (Dropout)        (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_231 (Conv2D)          (None, 32, 32, 64)        6208      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_232 (Conv2D)          (None, 16, 16, 64)        12352     \n",
            "_________________________________________________________________\n",
            "conv2d_233 (Conv2D)          (None, 16, 16, 96)        18528     \n",
            "_________________________________________________________________\n",
            "batch_normalization_140 (Bat (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "dropout_140 (Dropout)        (None, 16, 16, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_234 (Conv2D)          (None, 16, 16, 96)        27744     \n",
            "_________________________________________________________________\n",
            "conv2d_235 (Conv2D)          (None, 16, 16, 192)       55488     \n",
            "_________________________________________________________________\n",
            "batch_normalization_141 (Bat (None, 16, 16, 192)       768       \n",
            "_________________________________________________________________\n",
            "dropout_141 (Dropout)        (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_236 (Conv2D)          (None, 16, 16, 128)       24704     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_66 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_237 (Conv2D)          (None, 8, 8, 128)         49280     \n",
            "_________________________________________________________________\n",
            "conv2d_238 (Conv2D)          (None, 8, 8, 192)         73920     \n",
            "_________________________________________________________________\n",
            "batch_normalization_142 (Bat (None, 8, 8, 192)         768       \n",
            "_________________________________________________________________\n",
            "dropout_142 (Dropout)        (None, 8, 8, 192)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_239 (Conv2D)          (None, 8, 8, 192)         110784    \n",
            "_________________________________________________________________\n",
            "conv2d_240 (Conv2D)          (None, 8, 8, 384)         221568    \n",
            "_________________________________________________________________\n",
            "batch_normalization_143 (Bat (None, 8, 8, 384)         1536      \n",
            "_________________________________________________________________\n",
            "dropout_143 (Dropout)        (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_241 (Conv2D)          (None, 8, 8, 200)         77000     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_67 (MaxPooling (None, 4, 4, 200)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_242 (Conv2D)          (None, 4, 4, 100)         20100     \n",
            "_________________________________________________________________\n",
            "conv2d_243 (Conv2D)          (None, 1, 1, 10)          16010     \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_155 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 739,942\n",
            "Trainable params: 737,926\n",
            "Non-trainable params: 2,016\n",
            "_________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 68s 1ms/step - loss: 1.5450 - acc: 0.4418 - val_loss: 1.3829 - val_acc: 0.5096\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 1.0597 - acc: 0.6194 - val_loss: 1.2021 - val_acc: 0.5916\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.8540 - acc: 0.6993 - val_loss: 1.0259 - val_acc: 0.6517\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.7473 - acc: 0.7349 - val_loss: 0.9654 - val_acc: 0.6747\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.6641 - acc: 0.7680 - val_loss: 0.8383 - val_acc: 0.7269\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.6048 - acc: 0.7879 - val_loss: 0.8805 - val_acc: 0.7039\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.5522 - acc: 0.8050 - val_loss: 0.7385 - val_acc: 0.7554\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.5055 - acc: 0.8229 - val_loss: 0.8419 - val_acc: 0.7320\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.4732 - acc: 0.8331 - val_loss: 0.6714 - val_acc: 0.7661\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.4304 - acc: 0.8482 - val_loss: 0.7116 - val_acc: 0.7715\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.4087 - acc: 0.8552 - val_loss: 0.7592 - val_acc: 0.7631\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.3704 - acc: 0.8683 - val_loss: 0.7448 - val_acc: 0.7664\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.3432 - acc: 0.8793 - val_loss: 0.7084 - val_acc: 0.7671\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.3202 - acc: 0.8868 - val_loss: 0.6770 - val_acc: 0.7934\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2999 - acc: 0.8920 - val_loss: 0.6943 - val_acc: 0.7919\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2809 - acc: 0.9000 - val_loss: 0.8232 - val_acc: 0.7708\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2630 - acc: 0.9071 - val_loss: 0.7945 - val_acc: 0.7667\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2393 - acc: 0.9141 - val_loss: 0.8475 - val_acc: 0.7671\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2298 - acc: 0.9177 - val_loss: 0.6660 - val_acc: 0.8105\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 60s 1ms/step - loss: 0.2091 - acc: 0.9244 - val_loss: 0.8710 - val_acc: 0.7689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa77caffe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    }
  ]
}
