{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet_cifar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "outputId": "13701829-1a67-40df-a7df-cb4109aea0c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Hyperparameters\n",
        "#num_classes = 10\n",
        "# layers = 20\n",
        "# num_filter = 12\n",
        "# compression = 1\n",
        "# dropout_rate = 0.2\n",
        "\n",
        "dir=\"/content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/\"\n",
        "# mount the google drive to your Colab session\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "outputId": "c5d0fd54-ff7a-4092-a007-e6b0cc48c909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes = 10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions for Densenet model creation\n",
        "def add_denseblock(input, layers, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    temp = input\n",
        "\n",
        "    for _ in range(layers):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "def add_transition(input, num_filter = 12, dropout_rate = 0.2):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg\n",
        "\n",
        "def output_layer(input, classes):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx8Cjsxpz3w-",
        "colab_type": "text"
      },
      "source": [
        "#### Original layers is 40 which gives OOM. Layers=20, filters = 12\n",
        "\n",
        "batch_size=128 takes ~ 100s, batch_size=96 takes ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tvOdRiNk9Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "num_classes = 10\n",
        "num_layers = 20\n",
        "\n",
        "num_filter = 12\n",
        "compression = 1\n",
        "dropout_rate = 0.2\n",
        "\n",
        "class DensenetBuilder(object):\n",
        "  \n",
        "  @staticmethod\n",
        "  def build(input_shape, num_layers, num_outputs):    \n",
        "    input = Input(shape=(input_shape[0], input_shape[1], input_shape[2],))\n",
        "    conv1 = Conv2D(filters=12, kernel_size=(3,3), use_bias=False ,padding='same')(input)\n",
        "    print(\"conv1 shape \", conv1.shape)\n",
        "\n",
        "    print(\"Layers \", num_layers)\n",
        "    block1 = add_denseblock(conv1, num_layers, num_filter, dropout_rate)\n",
        "    print(\"block1 shape \", block1.shape)\n",
        "    tran1 = add_transition(block1, num_filter, dropout_rate)\n",
        "    print(\"tran1 shape \", tran1.shape)\n",
        "\n",
        "    block2 = add_denseblock(tran1, num_layers, num_filter, dropout_rate)\n",
        "    print(\"block2 shape \", block2.shape)\n",
        "    tran2 = add_transition(block2, num_filter, dropout_rate)\n",
        "    print(\"tran2 shape \", tran2.shape)\n",
        "\n",
        "    block3 = add_denseblock(tran2, num_layers, num_filter, dropout_rate)\n",
        "    print(\"block3 shape \", block3.shape)\n",
        "    tran3 = add_transition(block3, num_filter, dropout_rate)\n",
        "    print(\"tran3 shape \", tran3.shape)\n",
        "\n",
        "    block4 = add_denseblock(tran3, num_layers, num_filter, dropout_rate)\n",
        "    print(\"block4 shape \", block4.shape)\n",
        "    output = output_layer(block4, num_classes)\n",
        "    print(\"output shape \", output.shape)\n",
        "\n",
        "    model = Model(inputs=[input], outputs=[output])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "outputId": "dab7765d-67c3-4229-a2c6-5193ea1939e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = DensenetBuilder.build((img_height, img_width, channel), num_layers, num_classes)\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1 shape  (?, 32, 32, 12)\n",
            "Layers  20\n",
            "block1 shape  (?, 32, 32, 252)\n",
            "tran1 shape  (?, 16, 16, 12)\n",
            "block2 shape  (?, 16, 16, 252)\n",
            "tran2 shape  (?, 8, 8, 12)\n",
            "block3 shape  (?, 8, 8, 252)\n",
            "tran3 shape  (?, 4, 4, 12)\n",
            "block4 shape  (?, 4, 4, 252)\n",
            "output shape  (?, 10)\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 12)   324         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 32, 32, 12)   48          conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 32, 32, 12)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 12)   1296        activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_84 (Dropout)            (None, 32, 32, 12)   0           conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 32, 32, 24)   0           conv2d_85[0][0]                  \n",
            "                                                                 dropout_84[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 32, 32, 24)   96          concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 32, 32, 24)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 12)   2592        activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_85 (Dropout)            (None, 32, 32, 12)   0           conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 32, 32, 36)   0           concatenate_81[0][0]             \n",
            "                                                                 dropout_85[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 32, 32, 36)   144         concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 32, 32, 36)   0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 12)   3888        activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_86 (Dropout)            (None, 32, 32, 12)   0           conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 32, 32, 48)   0           concatenate_82[0][0]             \n",
            "                                                                 dropout_86[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 32, 32, 48)   192         concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 32, 32, 48)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 12)   5184        activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_87 (Dropout)            (None, 32, 32, 12)   0           conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 32, 32, 60)   0           concatenate_83[0][0]             \n",
            "                                                                 dropout_87[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 32, 32, 60)   240         concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 32, 32, 60)   0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 12)   6480        activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_88 (Dropout)            (None, 32, 32, 12)   0           conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 32, 32, 72)   0           concatenate_84[0][0]             \n",
            "                                                                 dropout_88[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 32, 32, 72)   288         concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 32, 32, 72)   0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 32, 32, 12)   7776        activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_89 (Dropout)            (None, 32, 32, 12)   0           conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_86 (Concatenate)    (None, 32, 32, 84)   0           concatenate_85[0][0]             \n",
            "                                                                 dropout_89[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 32, 32, 84)   336         concatenate_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 32, 32, 84)   0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 32, 32, 12)   9072        activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_90 (Dropout)            (None, 32, 32, 12)   0           conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_87 (Concatenate)    (None, 32, 32, 96)   0           concatenate_86[0][0]             \n",
            "                                                                 dropout_90[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 32, 32, 96)   384         concatenate_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 32, 32, 96)   0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 32, 32, 12)   10368       activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_91 (Dropout)            (None, 32, 32, 12)   0           conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_88 (Concatenate)    (None, 32, 32, 108)  0           concatenate_87[0][0]             \n",
            "                                                                 dropout_91[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 32, 32, 108)  432         concatenate_88[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 32, 32, 108)  0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 32, 32, 12)   11664       activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_92 (Dropout)            (None, 32, 32, 12)   0           conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_89 (Concatenate)    (None, 32, 32, 120)  0           concatenate_88[0][0]             \n",
            "                                                                 dropout_92[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 32, 32, 120)  480         concatenate_89[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 32, 32, 120)  0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 32, 32, 12)   12960       activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_93 (Dropout)            (None, 32, 32, 12)   0           conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_90 (Concatenate)    (None, 32, 32, 132)  0           concatenate_89[0][0]             \n",
            "                                                                 dropout_93[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 32, 32, 132)  528         concatenate_90[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 32, 32, 132)  0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 32, 32, 12)   14256       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_94 (Dropout)            (None, 32, 32, 12)   0           conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_91 (Concatenate)    (None, 32, 32, 144)  0           concatenate_90[0][0]             \n",
            "                                                                 dropout_94[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 32, 32, 144)  576         concatenate_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 32, 32, 144)  0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 32, 32, 12)   15552       activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_95 (Dropout)            (None, 32, 32, 12)   0           conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_92 (Concatenate)    (None, 32, 32, 156)  0           concatenate_91[0][0]             \n",
            "                                                                 dropout_95[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 32, 32, 156)  624         concatenate_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 32, 32, 156)  0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 32, 32, 12)   16848       activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_96 (Dropout)            (None, 32, 32, 12)   0           conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_93 (Concatenate)    (None, 32, 32, 168)  0           concatenate_92[0][0]             \n",
            "                                                                 dropout_96[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 32, 32, 168)  672         concatenate_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 32, 32, 168)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 32, 32, 12)   18144       activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_97 (Dropout)            (None, 32, 32, 12)   0           conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_94 (Concatenate)    (None, 32, 32, 180)  0           concatenate_93[0][0]             \n",
            "                                                                 dropout_97[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 32, 32, 180)  720         concatenate_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 32, 32, 180)  0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 32, 32, 12)   19440       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_98 (Dropout)            (None, 32, 32, 12)   0           conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_95 (Concatenate)    (None, 32, 32, 192)  0           concatenate_94[0][0]             \n",
            "                                                                 dropout_98[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 32, 32, 192)  768         concatenate_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 32, 32, 192)  0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 12)   20736       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_99 (Dropout)            (None, 32, 32, 12)   0           conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_96 (Concatenate)    (None, 32, 32, 204)  0           concatenate_95[0][0]             \n",
            "                                                                 dropout_99[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 32, 32, 204)  816         concatenate_96[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 32, 32, 204)  0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 32, 32, 12)   22032       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_100 (Dropout)           (None, 32, 32, 12)   0           conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_97 (Concatenate)    (None, 32, 32, 216)  0           concatenate_96[0][0]             \n",
            "                                                                 dropout_100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 32, 32, 216)  864         concatenate_97[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 32, 32, 216)  0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 32, 32, 12)   23328       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_101 (Dropout)           (None, 32, 32, 12)   0           conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_98 (Concatenate)    (None, 32, 32, 228)  0           concatenate_97[0][0]             \n",
            "                                                                 dropout_101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 32, 32, 228)  912         concatenate_98[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 32, 32, 228)  0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 32, 32, 12)   24624       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_102 (Dropout)           (None, 32, 32, 12)   0           conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_99 (Concatenate)    (None, 32, 32, 240)  0           concatenate_98[0][0]             \n",
            "                                                                 dropout_102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 240)  960         concatenate_99[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 32, 32, 240)  0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 12)   25920       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_103 (Dropout)           (None, 32, 32, 12)   0           conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_100 (Concatenate)   (None, 32, 32, 252)  0           concatenate_99[0][0]             \n",
            "                                                                 dropout_103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 252)  1008        concatenate_100[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 32, 32, 252)  0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 12)   3024        activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_104 (Dropout)           (None, 32, 32, 12)   0           conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 16, 16, 12)   0           dropout_104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 12)   48          average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 12)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 12)   1296        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_105 (Dropout)           (None, 16, 16, 12)   0           conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_101 (Concatenate)   (None, 16, 16, 24)   0           average_pooling2d_5[0][0]        \n",
            "                                                                 dropout_105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 24)   96          concatenate_101[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 24)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 12)   2592        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_106 (Dropout)           (None, 16, 16, 12)   0           conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_102 (Concatenate)   (None, 16, 16, 36)   0           concatenate_101[0][0]            \n",
            "                                                                 dropout_106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 36)   144         concatenate_102[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 36)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 12)   3888        activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_107 (Dropout)           (None, 16, 16, 12)   0           conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_103 (Concatenate)   (None, 16, 16, 48)   0           concatenate_102[0][0]            \n",
            "                                                                 dropout_107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 48)   192         concatenate_103[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 48)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 12)   5184        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_108 (Dropout)           (None, 16, 16, 12)   0           conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_104 (Concatenate)   (None, 16, 16, 60)   0           concatenate_103[0][0]            \n",
            "                                                                 dropout_108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 60)   240         concatenate_104[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 60)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 12)   6480        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_109 (Dropout)           (None, 16, 16, 12)   0           conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_105 (Concatenate)   (None, 16, 16, 72)   0           concatenate_104[0][0]            \n",
            "                                                                 dropout_109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 72)   288         concatenate_105[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 72)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 12)   7776        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_110 (Dropout)           (None, 16, 16, 12)   0           conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_106 (Concatenate)   (None, 16, 16, 84)   0           concatenate_105[0][0]            \n",
            "                                                                 dropout_110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 84)   336         concatenate_106[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 84)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 12)   9072        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_111 (Dropout)           (None, 16, 16, 12)   0           conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_107 (Concatenate)   (None, 16, 16, 96)   0           concatenate_106[0][0]            \n",
            "                                                                 dropout_111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 96)   384         concatenate_107[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 96)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 12)   10368       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_112 (Dropout)           (None, 16, 16, 12)   0           conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_108 (Concatenate)   (None, 16, 16, 108)  0           concatenate_107[0][0]            \n",
            "                                                                 dropout_112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 108)  432         concatenate_108[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 108)  0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 12)   11664       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_113 (Dropout)           (None, 16, 16, 12)   0           conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_109 (Concatenate)   (None, 16, 16, 120)  0           concatenate_108[0][0]            \n",
            "                                                                 dropout_113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 120)  480         concatenate_109[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 120)  0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 12)   12960       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_114 (Dropout)           (None, 16, 16, 12)   0           conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_110 (Concatenate)   (None, 16, 16, 132)  0           concatenate_109[0][0]            \n",
            "                                                                 dropout_114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 132)  528         concatenate_110[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 132)  0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 12)   14256       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_115 (Dropout)           (None, 16, 16, 12)   0           conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_111 (Concatenate)   (None, 16, 16, 144)  0           concatenate_110[0][0]            \n",
            "                                                                 dropout_115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 144)  576         concatenate_111[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 144)  0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 12)   15552       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_116 (Dropout)           (None, 16, 16, 12)   0           conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 16, 16, 156)  0           concatenate_111[0][0]            \n",
            "                                                                 dropout_116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 156)  624         concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 156)  0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 12)   16848       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_117 (Dropout)           (None, 16, 16, 12)   0           conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 16, 16, 168)  0           concatenate_112[0][0]            \n",
            "                                                                 dropout_117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 168)  672         concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 168)  0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 16, 16, 12)   18144       activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_118 (Dropout)           (None, 16, 16, 12)   0           conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 16, 16, 180)  0           concatenate_113[0][0]            \n",
            "                                                                 dropout_118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 180)  720         concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 16, 16, 180)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 12)   19440       activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_119 (Dropout)           (None, 16, 16, 12)   0           conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_115 (Concatenate)   (None, 16, 16, 192)  0           concatenate_114[0][0]            \n",
            "                                                                 dropout_119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 192)  768         concatenate_115[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 192)  0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 12)   20736       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_120 (Dropout)           (None, 16, 16, 12)   0           conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_116 (Concatenate)   (None, 16, 16, 204)  0           concatenate_115[0][0]            \n",
            "                                                                 dropout_120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 204)  816         concatenate_116[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 204)  0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 12)   22032       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_121 (Dropout)           (None, 16, 16, 12)   0           conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_117 (Concatenate)   (None, 16, 16, 216)  0           concatenate_116[0][0]            \n",
            "                                                                 dropout_121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 216)  864         concatenate_117[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 16, 16, 216)  0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 12)   23328       activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_122 (Dropout)           (None, 16, 16, 12)   0           conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_118 (Concatenate)   (None, 16, 16, 228)  0           concatenate_117[0][0]            \n",
            "                                                                 dropout_122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 228)  912         concatenate_118[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 16, 16, 228)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 12)   24624       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_123 (Dropout)           (None, 16, 16, 12)   0           conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_119 (Concatenate)   (None, 16, 16, 240)  0           concatenate_118[0][0]            \n",
            "                                                                 dropout_123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 240)  960         concatenate_119[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 16, 16, 240)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 12)   25920       activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_124 (Dropout)           (None, 16, 16, 12)   0           conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_120 (Concatenate)   (None, 16, 16, 252)  0           concatenate_119[0][0]            \n",
            "                                                                 dropout_124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 252)  1008        concatenate_120[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 16, 16, 252)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 12)   3024        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_125 (Dropout)           (None, 16, 16, 12)   0           conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 8, 8, 12)     0           dropout_125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 8, 8, 12)     48          average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 8, 8, 12)     0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 8, 8, 12)     1296        activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_126 (Dropout)           (None, 8, 8, 12)     0           conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_121 (Concatenate)   (None, 8, 8, 24)     0           average_pooling2d_6[0][0]        \n",
            "                                                                 dropout_126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 8, 8, 24)     96          concatenate_121[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 8, 8, 24)     0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 8, 8, 12)     2592        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_127 (Dropout)           (None, 8, 8, 12)     0           conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_122 (Concatenate)   (None, 8, 8, 36)     0           concatenate_121[0][0]            \n",
            "                                                                 dropout_127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 8, 8, 36)     144         concatenate_122[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 8, 8, 36)     0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 8, 8, 12)     3888        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_128 (Dropout)           (None, 8, 8, 12)     0           conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_123 (Concatenate)   (None, 8, 8, 48)     0           concatenate_122[0][0]            \n",
            "                                                                 dropout_128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 8, 8, 48)     192         concatenate_123[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 8, 8, 48)     0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 8, 8, 12)     5184        activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_129 (Dropout)           (None, 8, 8, 12)     0           conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_124 (Concatenate)   (None, 8, 8, 60)     0           concatenate_123[0][0]            \n",
            "                                                                 dropout_129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 8, 8, 60)     240         concatenate_124[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 8, 8, 60)     0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 8, 8, 12)     6480        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_130 (Dropout)           (None, 8, 8, 12)     0           conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_125 (Concatenate)   (None, 8, 8, 72)     0           concatenate_124[0][0]            \n",
            "                                                                 dropout_130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 8, 8, 72)     288         concatenate_125[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 8, 8, 72)     0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 8, 8, 12)     7776        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_131 (Dropout)           (None, 8, 8, 12)     0           conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_126 (Concatenate)   (None, 8, 8, 84)     0           concatenate_125[0][0]            \n",
            "                                                                 dropout_131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 8, 8, 84)     336         concatenate_126[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 8, 8, 84)     0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 8, 8, 12)     9072        activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_132 (Dropout)           (None, 8, 8, 12)     0           conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_127 (Concatenate)   (None, 8, 8, 96)     0           concatenate_126[0][0]            \n",
            "                                                                 dropout_132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 8, 8, 96)     384         concatenate_127[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 8, 8, 96)     0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 8, 8, 12)     10368       activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_133 (Dropout)           (None, 8, 8, 12)     0           conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_128 (Concatenate)   (None, 8, 8, 108)    0           concatenate_127[0][0]            \n",
            "                                                                 dropout_133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 8, 8, 108)    432         concatenate_128[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 8, 8, 108)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 8, 8, 12)     11664       activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_134 (Dropout)           (None, 8, 8, 12)     0           conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_129 (Concatenate)   (None, 8, 8, 120)    0           concatenate_128[0][0]            \n",
            "                                                                 dropout_134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 8, 8, 120)    480         concatenate_129[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 8, 8, 120)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 8, 8, 12)     12960       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_135 (Dropout)           (None, 8, 8, 12)     0           conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_130 (Concatenate)   (None, 8, 8, 132)    0           concatenate_129[0][0]            \n",
            "                                                                 dropout_135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 8, 8, 132)    528         concatenate_130[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 8, 8, 132)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 8, 8, 12)     14256       activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_136 (Dropout)           (None, 8, 8, 12)     0           conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_131 (Concatenate)   (None, 8, 8, 144)    0           concatenate_130[0][0]            \n",
            "                                                                 dropout_136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 8, 8, 144)    576         concatenate_131[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 8, 8, 144)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 8, 8, 12)     15552       activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_137 (Dropout)           (None, 8, 8, 12)     0           conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_132 (Concatenate)   (None, 8, 8, 156)    0           concatenate_131[0][0]            \n",
            "                                                                 dropout_137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 8, 8, 156)    624         concatenate_132[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 8, 8, 156)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 8, 8, 12)     16848       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_138 (Dropout)           (None, 8, 8, 12)     0           conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_133 (Concatenate)   (None, 8, 8, 168)    0           concatenate_132[0][0]            \n",
            "                                                                 dropout_138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 8, 8, 168)    672         concatenate_133[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 8, 8, 168)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 8, 8, 12)     18144       activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_139 (Dropout)           (None, 8, 8, 12)     0           conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_134 (Concatenate)   (None, 8, 8, 180)    0           concatenate_133[0][0]            \n",
            "                                                                 dropout_139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 8, 8, 180)    720         concatenate_134[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 8, 8, 180)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 8, 8, 12)     19440       activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_140 (Dropout)           (None, 8, 8, 12)     0           conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_135 (Concatenate)   (None, 8, 8, 192)    0           concatenate_134[0][0]            \n",
            "                                                                 dropout_140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 8, 8, 192)    768         concatenate_135[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 8, 8, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 8, 8, 12)     20736       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_141 (Dropout)           (None, 8, 8, 12)     0           conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_136 (Concatenate)   (None, 8, 8, 204)    0           concatenate_135[0][0]            \n",
            "                                                                 dropout_141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 8, 8, 204)    816         concatenate_136[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 8, 8, 204)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 8, 8, 12)     22032       activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_142 (Dropout)           (None, 8, 8, 12)     0           conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_137 (Concatenate)   (None, 8, 8, 216)    0           concatenate_136[0][0]            \n",
            "                                                                 dropout_142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 8, 8, 216)    864         concatenate_137[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 8, 8, 216)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 8, 8, 12)     23328       activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_143 (Dropout)           (None, 8, 8, 12)     0           conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_138 (Concatenate)   (None, 8, 8, 228)    0           concatenate_137[0][0]            \n",
            "                                                                 dropout_143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 8, 8, 228)    912         concatenate_138[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 8, 8, 228)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 8, 8, 12)     24624       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_144 (Dropout)           (None, 8, 8, 12)     0           conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_139 (Concatenate)   (None, 8, 8, 240)    0           concatenate_138[0][0]            \n",
            "                                                                 dropout_144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 8, 8, 240)    960         concatenate_139[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 8, 8, 240)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 8, 8, 12)     25920       activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_145 (Dropout)           (None, 8, 8, 12)     0           conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_140 (Concatenate)   (None, 8, 8, 252)    0           concatenate_139[0][0]            \n",
            "                                                                 dropout_145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 8, 8, 252)    1008        concatenate_140[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 8, 8, 252)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 8, 8, 12)     3024        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_146 (Dropout)           (None, 8, 8, 12)     0           conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 4, 4, 12)     0           dropout_146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 4, 4, 12)     48          average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 4, 4, 12)     0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 4, 4, 12)     1296        activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_147 (Dropout)           (None, 4, 4, 12)     0           conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_141 (Concatenate)   (None, 4, 4, 24)     0           average_pooling2d_7[0][0]        \n",
            "                                                                 dropout_147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 4, 4, 24)     96          concatenate_141[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 4, 4, 24)     0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 4, 4, 12)     2592        activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_148 (Dropout)           (None, 4, 4, 12)     0           conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_142 (Concatenate)   (None, 4, 4, 36)     0           concatenate_141[0][0]            \n",
            "                                                                 dropout_148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 4, 4, 36)     144         concatenate_142[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 4, 4, 36)     0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 4, 4, 12)     3888        activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_149 (Dropout)           (None, 4, 4, 12)     0           conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_143 (Concatenate)   (None, 4, 4, 48)     0           concatenate_142[0][0]            \n",
            "                                                                 dropout_149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 4, 4, 48)     192         concatenate_143[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 4, 4, 48)     0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 4, 4, 12)     5184        activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_150 (Dropout)           (None, 4, 4, 12)     0           conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 4, 4, 60)     0           concatenate_143[0][0]            \n",
            "                                                                 dropout_150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 4, 4, 60)     240         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 4, 4, 60)     0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 4, 4, 12)     6480        activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_151 (Dropout)           (None, 4, 4, 12)     0           conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_145 (Concatenate)   (None, 4, 4, 72)     0           concatenate_144[0][0]            \n",
            "                                                                 dropout_151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 4, 4, 72)     288         concatenate_145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 4, 4, 72)     0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 4, 4, 12)     7776        activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_152 (Dropout)           (None, 4, 4, 12)     0           conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_146 (Concatenate)   (None, 4, 4, 84)     0           concatenate_145[0][0]            \n",
            "                                                                 dropout_152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 4, 4, 84)     336         concatenate_146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 4, 4, 84)     0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 4, 4, 12)     9072        activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_153 (Dropout)           (None, 4, 4, 12)     0           conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_147 (Concatenate)   (None, 4, 4, 96)     0           concatenate_146[0][0]            \n",
            "                                                                 dropout_153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 4, 4, 96)     384         concatenate_147[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 4, 4, 96)     0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 4, 4, 12)     10368       activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_154 (Dropout)           (None, 4, 4, 12)     0           conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_148 (Concatenate)   (None, 4, 4, 108)    0           concatenate_147[0][0]            \n",
            "                                                                 dropout_154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 4, 4, 108)    432         concatenate_148[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 4, 4, 108)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 4, 4, 12)     11664       activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_155 (Dropout)           (None, 4, 4, 12)     0           conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_149 (Concatenate)   (None, 4, 4, 120)    0           concatenate_148[0][0]            \n",
            "                                                                 dropout_155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 4, 4, 120)    480         concatenate_149[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 4, 4, 120)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 4, 4, 12)     12960       activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_156 (Dropout)           (None, 4, 4, 12)     0           conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_150 (Concatenate)   (None, 4, 4, 132)    0           concatenate_149[0][0]            \n",
            "                                                                 dropout_156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 4, 4, 132)    528         concatenate_150[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 4, 4, 132)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 4, 4, 12)     14256       activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_157 (Dropout)           (None, 4, 4, 12)     0           conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_151 (Concatenate)   (None, 4, 4, 144)    0           concatenate_150[0][0]            \n",
            "                                                                 dropout_157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 4, 4, 144)    576         concatenate_151[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 4, 4, 144)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 4, 4, 12)     15552       activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_158 (Dropout)           (None, 4, 4, 12)     0           conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_152 (Concatenate)   (None, 4, 4, 156)    0           concatenate_151[0][0]            \n",
            "                                                                 dropout_158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 4, 4, 156)    624         concatenate_152[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 4, 4, 156)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 4, 4, 12)     16848       activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_159 (Dropout)           (None, 4, 4, 12)     0           conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_153 (Concatenate)   (None, 4, 4, 168)    0           concatenate_152[0][0]            \n",
            "                                                                 dropout_159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 4, 4, 168)    672         concatenate_153[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 4, 4, 168)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 4, 4, 12)     18144       activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_160 (Dropout)           (None, 4, 4, 12)     0           conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_154 (Concatenate)   (None, 4, 4, 180)    0           concatenate_153[0][0]            \n",
            "                                                                 dropout_160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 4, 4, 180)    720         concatenate_154[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 4, 4, 180)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 4, 4, 12)     19440       activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_161 (Dropout)           (None, 4, 4, 12)     0           conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_155 (Concatenate)   (None, 4, 4, 192)    0           concatenate_154[0][0]            \n",
            "                                                                 dropout_161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 4, 4, 192)    768         concatenate_155[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 4, 4, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 4, 4, 12)     20736       activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_162 (Dropout)           (None, 4, 4, 12)     0           conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_156 (Concatenate)   (None, 4, 4, 204)    0           concatenate_155[0][0]            \n",
            "                                                                 dropout_162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 4, 4, 204)    816         concatenate_156[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 4, 4, 204)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 4, 4, 12)     22032       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_163 (Dropout)           (None, 4, 4, 12)     0           conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_157 (Concatenate)   (None, 4, 4, 216)    0           concatenate_156[0][0]            \n",
            "                                                                 dropout_163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 4, 4, 216)    864         concatenate_157[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 4, 4, 216)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 4, 4, 12)     23328       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_164 (Dropout)           (None, 4, 4, 12)     0           conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_158 (Concatenate)   (None, 4, 4, 228)    0           concatenate_157[0][0]            \n",
            "                                                                 dropout_164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 4, 4, 228)    912         concatenate_158[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 4, 4, 228)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 4, 4, 12)     24624       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_165 (Dropout)           (None, 4, 4, 12)     0           conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_159 (Concatenate)   (None, 4, 4, 240)    0           concatenate_158[0][0]            \n",
            "                                                                 dropout_165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 4, 4, 240)    960         concatenate_159[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 4, 4, 240)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 4, 4, 12)     25920       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_166 (Dropout)           (None, 4, 4, 12)     0           conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_160 (Concatenate)   (None, 4, 4, 252)    0           concatenate_159[0][0]            \n",
            "                                                                 dropout_166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 4, 4, 252)    1008        concatenate_160[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 4, 4, 252)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 2, 2, 252)    0           activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1008)         0           average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           10090       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,152,478\n",
            "Trainable params: 1,130,302\n",
            "Non-trainable params: 22,176\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "outputId": "410f1fda-b48b-4a46-bafc-2c3cb42d9331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "file = dir + \"Densenet_cifar.{epoch:02d}-{val_acc:.4f}.hdf5\" \n",
        "checkpoint = ModelCheckpoint(file, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "batch_size = 128\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=20, verbose=1, \n",
        "          validation_data=(x_test, y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 129s 3ms/step - loss: 1.5720 - acc: 0.4170 - val_loss: 1.4453 - val_acc: 0.5019\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.50190, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.01-0.5019.hdf5\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 1.1566 - acc: 0.5798 - val_loss: 1.4243 - val_acc: 0.5164\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.50190 to 0.51640, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.02-0.5164.hdf5\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.9686 - acc: 0.6522 - val_loss: 3.4266 - val_acc: 0.3634\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.51640\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.8590 - acc: 0.6921 - val_loss: 1.6123 - val_acc: 0.5647\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.51640 to 0.56470, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.04-0.5647.hdf5\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.7753 - acc: 0.7232 - val_loss: 1.4477 - val_acc: 0.6092\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.56470 to 0.60920, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.05-0.6092.hdf5\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.7096 - acc: 0.7481 - val_loss: 1.4417 - val_acc: 0.5998\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.60920\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.6522 - acc: 0.7704 - val_loss: 0.9819 - val_acc: 0.6890\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.60920 to 0.68900, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.07-0.6890.hdf5\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.6155 - acc: 0.7850 - val_loss: 0.8009 - val_acc: 0.7570\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.68900 to 0.75700, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.08-0.7570.hdf5\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.5704 - acc: 0.7983 - val_loss: 0.8154 - val_acc: 0.7436\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.75700\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.5366 - acc: 0.8125 - val_loss: 1.1052 - val_acc: 0.6898\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.75700\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.5079 - acc: 0.8209 - val_loss: 0.7364 - val_acc: 0.7664\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.75700 to 0.76640, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.11-0.7664.hdf5\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.4854 - acc: 0.8295 - val_loss: 1.4026 - val_acc: 0.6600\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.76640\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.4627 - acc: 0.8374 - val_loss: 1.1903 - val_acc: 0.6881\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.76640\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.4407 - acc: 0.8451 - val_loss: 0.7825 - val_acc: 0.7704\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.76640 to 0.77040, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.14-0.7704.hdf5\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.4215 - acc: 0.8514 - val_loss: 0.8649 - val_acc: 0.7735\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.77040 to 0.77350, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.15-0.7735.hdf5\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.4014 - acc: 0.8592 - val_loss: 0.7745 - val_acc: 0.7728\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.77350\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3871 - acc: 0.8662 - val_loss: 0.8415 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00017: val_acc improved from 0.77350 to 0.77360, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.17-0.7736.hdf5\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3700 - acc: 0.8711 - val_loss: 1.0452 - val_acc: 0.7372\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.77360\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3591 - acc: 0.8741 - val_loss: 0.6101 - val_acc: 0.8289\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.77360 to 0.82890, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.19-0.8289.hdf5\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3415 - acc: 0.8802 - val_loss: 0.6267 - val_acc: 0.8204\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.82890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6299a17b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGQwlybWIZW2",
        "colab_type": "code",
        "outputId": "7731a8b8-f67c-4140-b5cd-210a2ba76e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_info = model.fit(x_train, y_train, batch_size=batch_size, initial_epoch=20, epochs=50, verbose=1, \n",
        "          validation_data=(x_test, y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3269 - acc: 0.8849 - val_loss: 0.7152 - val_acc: 0.8066\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.82890\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3147 - acc: 0.8891 - val_loss: 1.3214 - val_acc: 0.7077\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.82890\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.3086 - acc: 0.8923 - val_loss: 0.5979 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.82890 to 0.83260, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.23-0.8326.hdf5\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2967 - acc: 0.8956 - val_loss: 0.8151 - val_acc: 0.7899\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.83260\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2845 - acc: 0.8994 - val_loss: 0.5624 - val_acc: 0.8459\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.83260 to 0.84590, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.25-0.8459.hdf5\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2755 - acc: 0.9025 - val_loss: 1.0660 - val_acc: 0.7488\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.84590\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2698 - acc: 0.9040 - val_loss: 0.8102 - val_acc: 0.8054\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.84590\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2525 - acc: 0.9107 - val_loss: 0.8453 - val_acc: 0.7931\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.84590\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2524 - acc: 0.9104 - val_loss: 0.8952 - val_acc: 0.7859\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.84590\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 103s 2ms/step - loss: 0.2377 - acc: 0.9160 - val_loss: 1.1586 - val_acc: 0.7674\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.84590\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 103s 2ms/step - loss: 0.2351 - acc: 0.9161 - val_loss: 0.6424 - val_acc: 0.8303\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.84590\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2277 - acc: 0.9202 - val_loss: 0.8524 - val_acc: 0.8105\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.84590\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2200 - acc: 0.9208 - val_loss: 0.8142 - val_acc: 0.8022\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.84590\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2115 - acc: 0.9253 - val_loss: 0.7510 - val_acc: 0.8212\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.84590\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.2088 - acc: 0.9241 - val_loss: 0.9989 - val_acc: 0.7816\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.84590\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1973 - acc: 0.9295 - val_loss: 1.1364 - val_acc: 0.7610\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.84590\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1938 - acc: 0.9308 - val_loss: 0.7258 - val_acc: 0.8326\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.84590\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1889 - acc: 0.9315 - val_loss: 0.7725 - val_acc: 0.8274\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.84590\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1844 - acc: 0.9343 - val_loss: 0.8503 - val_acc: 0.8102\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.84590\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1833 - acc: 0.9340 - val_loss: 0.7193 - val_acc: 0.8338\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.84590\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1783 - acc: 0.9357 - val_loss: 0.8394 - val_acc: 0.8223\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.84590\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1701 - acc: 0.9391 - val_loss: 0.9188 - val_acc: 0.8152\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.84590\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1613 - acc: 0.9416 - val_loss: 0.8261 - val_acc: 0.8217\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.84590\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 102s 2ms/step - loss: 0.1589 - acc: 0.9433 - val_loss: 1.0157 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.84590\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1549 - acc: 0.9438 - val_loss: 1.0259 - val_acc: 0.8028\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.84590\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1517 - acc: 0.9461 - val_loss: 0.8728 - val_acc: 0.8224\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.84590\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1453 - acc: 0.9483 - val_loss: 0.8046 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.84590\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1520 - acc: 0.9451 - val_loss: 0.7049 - val_acc: 0.8504\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.84590 to 0.85040, saving model to /content/gdrive/My Drive/Colab Notebooks/EVA/Cifar/Weights/Densenet_cifar.48-0.8504.hdf5\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1394 - acc: 0.9509 - val_loss: 1.3711 - val_acc: 0.7542\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.85040\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 101s 2ms/step - loss: 0.1364 - acc: 0.9513 - val_loss: 0.7639 - val_acc: 0.8345\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.85040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTHypVVoXGXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(10,4))\n",
        "    # Set axis properties [xmin, xmax, ymin, ymax]\n",
        "    axs[0].axis([0,50,0.4,1])\n",
        "    \n",
        "    # Plot training & validation accuracy values\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    #axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    \n",
        "    # Plot training & validation loss values\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    #axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAbO3m2hXRT0",
        "colab_type": "code",
        "outputId": "61a12030-96f4-4fe2-c781-818592ac7667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plot_model_history(model_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAEWCAYAAAAuOkCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcWydmIVhZGr",
        "colab_type": "code",
        "outputId": "83831bcb-4d50-43bd-c9a3-4c0c54f6b90c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# Load and test the model \n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(dir + \"Densenet_cifar.48-0.8504.hdf5\")\n",
        "print(\"Loaded weights from disk \", model)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Loaded weights from disk  <keras.engine.training.Model object at 0x7ff7b5806ac8>\n",
            "10000/10000 [==============================] - 35s 4ms/step\n",
            "[0.7049287597775459, 0.8504]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}